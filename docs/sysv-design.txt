GASNet system V shared memory design thoughts
---------------------------------------------
by: Dan Bonachea <bonachea@cs.berkeley.edu>
$Revision: 1.1 $

Scope:

* GASNet/SysV only be supported for SEGMENT_FAST or LARGE (not meaningful for EVERYTHING mode)
* UPC will only use it without pthreads, but GASNet can also support pthreads

Terminology:

* node: each UNIX process running gasnet
* supernode: collection of 1 or more nodes with cross-mapped segments using sysv support
* supernode peers: nodes which share a supernode
* supersegment: the (possibly discontiguous) memory region containing all the cross-mapped segments within a supernode

Interface notes:

* All node processes call gasnet_init(), each is a separate GASNet node
* Some indicator tells gasnet_init that System V is in effect - either an environment flag or simply a library compile-time indicator
* gasnet_init performs super-node discovery, using OS-appropriate mechanisms to figure out which nodes are capable of sharing memory with which other nodes
* MaxLocal/Global return values reflecting the amount of segment space divided evenly among the supernode peers, and each node passes a size to gasnet_attach reflecting the per-node segment size they want.
* gasnet_attach takes care of mapping each processor's segments as usual, but also
  maps the segments of supernode peers into each nodes VM space using sysV or other OS-appropriate mechanisms.
* All nodes on a supernode have the same virtual address map of the segments on that supernode
  - is this always possible to guarantee?
* Client calls getSegmentInfo to get the location of his segment and those of other nodes
* seginfo_t for node X reflects the shared segment belonging to X, but also includes a supernode identifier so nodes can see which nodes share their supernode
* nodes may directly load/store into the segments of any node sharing their supernode 
* remotely-addressable segment restrictions on gasnet_put/get/AMLong apply to the individual segments - ie gasnet_put() to an address in the segment of node X must give node X as the target node, not some other supernode peer
* sysv segments of a supernode probably not guaranteed to be adjacent in VM
  - provide a definition of GASNET_CONTIGUOUS_SUPERSEGMENT when it's known at compile-time to be contiguous

Restrictions:

* gasnet_hsl_t's are node-local and while they may reside in the segment, they may not be accessed by more than one node in a supernode
  - we can/should add a debug-mode check for this (also applies to shmem-conduit)

Open questions:

* Do we need a separate build or separate configure of libgasnet and/or libupcr with sysv enabled/disabled?
  - probably add a sysv-seq library build, so that user can select sysv support at UPC app build time
* If we want to use the same build, then how should GASNET_ALIGNED_SEGMENTS definition behave? Never true when any supernode contains more than one node, but don't know that until runtime. 
   - probably add a new GASNET_ALIGNED_SUPERSEGMENTS to indicate when supersegs are aligned across nodes
* Can we get away with always connecting SysV segments after all processes are created, or do we need to fork after setting up shared memory segments? Will drivers & spawners even allow that? 
* If we decide that a fork is required after job launch, then it should definitely be done by the conduit, not the client code. But how would the interface look? (this would very likely break MPI interoperability)
* Does the client code between init/attach need to know the supernode associations? (eg to make segsize decision)
* How do we handle 8 or 16-way SMPs on 32-bit platforms where VM space is already tight, or OS's where the limit on SysV shareable memory is small? This design would make our per-node segsizes rather small. Do we want a mode where segments are not cross-mapped, but the gasnet_put/get can bypass the NIC using a two-copy scheme through SysV bounce buffers? 
  - This bounce buffer mode could potentially also help for EVERYTHING mode (without sysv segments), although due to attentiveness issues, it may be slower than using loopback RDMA
* Do we ever want to allow supernodes to share a physical node? (eg to increase shared heap size)
  - if so, need an interface to specify this (probably environment variables)
* Will there be contention with MPI for sysv resources?
* Can we still get allocate on first write mapping for the segment?
  - If so, who's responsible for establishing processor/memory affinity with first touch? (probably the client)
* Can firehose safely pin and unpin pages in SysV segment?  
  - Does firehose need to know about supernode associations in order to maintain the sysv mapping?
  - Easy solution is to only support FAST mode for sysv on pinning-based conduits, so firehose never needs to mess with segment mapping after startup
  
ToDo:

* Look into OS limits on sysv segment sizes, available mechanisms for sharing, and driver/spawner restrictions on fork
* Look at how ARMCI does it
* Find a way to probe for largest possible sysV segment without dying with an out of memory fault

GASNet implementation notes:

* Have a configure --enable-sysv that enables all this functionality.
* gasnet_init/attach will obviously need changes on each conduit to make this work, although we can hopefully encapsulate the ugliest parts in conduit-independent modules
  - start with smp-conduit, and factor things wherever possible
* gasnet_put/get to supernode peers will automatically bypass through shared memory in the same way we currently have same-node loopback
* Have a unified code base for sending/recving AM messages as opaque buffers through shared memory bypass - conduits can use this or implement their own supernode loopback.
* rest of GASNet implementation should never need to know about supernode peer mappings

